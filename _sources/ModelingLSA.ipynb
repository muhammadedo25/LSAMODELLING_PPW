{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topik Medelling dengan Jupyter Notebook dengan menggunakan metode LSA (Latent Semantic Analysis) pada jurnal PTA Trunojoyo Ekonomi - Manajemen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah-langkah yang dilakukan adalah sebagai berikut : <br>\n",
    "1 Pre-Processing\n",
    "    <ul>\n",
    "        <li> pengecekan missing value\n",
    "        <li> Melakukan Stopword\n",
    "        <li> Melakukan Proses TF-IDF \n",
    "    </ul>\n",
    "2 Penerapan model LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing adalah proses yang mengubah data mentah ke dalam bentuk yang lebih mudah dipahami. Proses ini dilakukan karena data mentah sering kali tidak memiliki format yang teratur. Proses ini dilakukan untuk mempersiapkan data mentah menjadi data siap pakai kedalam format yang berguna dan efisien dengan metode/ model yang akan digunakan. Dengan begitu, data tersebut dapat dilakukan untuk proses selanjutnya yaitu analisis data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <li> Pengecekan Missing Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Value merupakan hilangnya beberapa data yang di peroleh. Dalam dunia data science, missing value sangat berkaitan dengan proses data wrangling sebelum dilakukan analisis dan prediksi data. Data wrangling merupakan kegiatan penyeragaman data atau pembersihan data (cleaning data) dari data kotor (mentah) menjadi data yang nantinya siap digunakan untuk analisis. Data kotor (mentah) yang dimaksud adalah data yang terindikasi masih terdapat ketidakseragaman format, muncul missing values pada data, dan masih juga ditemukan adanya tambahan sufiks, prefiks dan lain-lain. <br><br>\n",
    "Untuk proses pengidentifikasian missing value bisa dilihat dari proses dibawah ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> import dan baca dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judul</th>\n",
       "      <th>Penulis</th>\n",
       "      <th>Dosbing_1</th>\n",
       "      <th>Dosbing_2</th>\n",
       "      <th>Abstrak_indo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PELAPORAN BIAYA KUALITAS UNTUK MEMINIMALKAN TE...</td>\n",
       "      <td>M. Boy Singgih Gitayuda</td>\n",
       "      <td>Drs. Ec. Makhmud Zulkifli, M.Si</td>\n",
       "      <td>rasetyo Nugroho,. S.Pi., MM</td>\n",
       "      <td>ABSTRAK\\r\\n\\r\\nPenelitian ini mengungkapkan be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PENGARUH RETAILING MIX (BAURAN ECERAN) TERHADA...</td>\n",
       "      <td>Ali Usman</td>\n",
       "      <td>Dr. Ir. Nurita Andriani, MM</td>\n",
       "      <td>adi Purnomo, SE., MM</td>\n",
       "      <td>Bauran eceran merupakan salah satu langkah pem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PENGARUH CELEBRITY ENDORSER IWAN FALS TERHADAP...</td>\n",
       "      <td>Tayyi Matun</td>\n",
       "      <td>Bambang Setiyo Pambudi</td>\n",
       "      <td>ustina Chrismardani</td>\n",
       "      <td>Tujuan penelitian ini adalah mengetahui pengar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pengaruh Harga dan Kualitas Pelayanan terhadap...</td>\n",
       "      <td>ALI RAHBINI</td>\n",
       "      <td>PRIBANUS WANTARA</td>\n",
       "      <td>IRMA KURRIWATI</td>\n",
       "      <td>Ali Rahbini, Pengaruh Harga dan Kualitas Pelay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pengaruh Retailing Mix terhadap Keputusan Pemb...</td>\n",
       "      <td>Fitriyah</td>\n",
       "      <td>Dr. H. Pribanus Wantara, Drs., MM</td>\n",
       "      <td>ustina Chrismardani, S.Si., MM</td>\n",
       "      <td>Tujuan penelitian ini adalah untuk mengetahui ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Judul                  Penulis  \\\n",
       "0  PELAPORAN BIAYA KUALITAS UNTUK MEMINIMALKAN TE...  M. Boy Singgih Gitayuda   \n",
       "1  PENGARUH RETAILING MIX (BAURAN ECERAN) TERHADA...                Ali Usman   \n",
       "2  PENGARUH CELEBRITY ENDORSER IWAN FALS TERHADAP...              Tayyi Matun   \n",
       "3  Pengaruh Harga dan Kualitas Pelayanan terhadap...              ALI RAHBINI   \n",
       "4  Pengaruh Retailing Mix terhadap Keputusan Pemb...                 Fitriyah   \n",
       "\n",
       "                           Dosbing_1                       Dosbing_2  \\\n",
       "0    Drs. Ec. Makhmud Zulkifli, M.Si     rasetyo Nugroho,. S.Pi., MM   \n",
       "1        Dr. Ir. Nurita Andriani, MM            adi Purnomo, SE., MM   \n",
       "2             Bambang Setiyo Pambudi             ustina Chrismardani   \n",
       "3                   PRIBANUS WANTARA                  IRMA KURRIWATI   \n",
       "4  Dr. H. Pribanus Wantara, Drs., MM  ustina Chrismardani, S.Si., MM   \n",
       "\n",
       "                                        Abstrak_indo  \n",
       "0  ABSTRAK\\r\\n\\r\\nPenelitian ini mengungkapkan be...  \n",
       "1  Bauran eceran merupakan salah satu langkah pem...  \n",
       "2  Tujuan penelitian ini adalah mengetahui pengar...  \n",
       "3  Ali Rahbini, Pengaruh Harga dan Kualitas Pelay...  \n",
       "4  Tujuan penelitian ini adalah untuk mengetahui ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Script diatas untuk melakukan pengecekan jumlah tabel (row, kolom) dari dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Judul           0\n",
       "Penulis         0\n",
       "Dosbing_1       0\n",
       "Dosbing_2       0\n",
       "Abstrak_indo    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(data.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">kode diatas untuk melakukan pengecekan missing value pada masing-masing fiturnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari proses pengecekan diatas, dapat diketahui bahwa dataset yang dimiliki terdapat 10 jumlah dokumen dengan 5 fitur <br>\n",
    "Dan tidak ada data yang hilang didalam dataset ini, sehingga tidak perlu dilakukan pemrosesan metode apapun untuk menangani missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <li> Melakukan Stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam tahap ini, dataset yang sudah siap dipakai, yakni data pada fitur \"Abstrak_indo\". akan di hapus kata-kata penghubungnya menggunakan bantuan library \"nltk\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('popular')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = data['Abstrak_indo']\n",
    "contents = contents.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Script diatas digunakan untuk mengambil data dari fitur \"Abstrak_indo\", dan lakukan pemrosesan alphabet huruf kecil dari datanya agar sesuai dengan library stopword dari \"nltk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopping_word(contents):    \n",
    "    data_kata = []\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words2 = stopwords.words('indonesian')\n",
    "    stop_words.extend(stop_words2)\n",
    "    jmlData = contents.shape \n",
    "    for i in range(jmlData[0]):\n",
    "        word_tokens = word_tokenize(contents[i])\n",
    "        # print(word_tokens)\n",
    "            \n",
    "        word_tokens_no_stopwords = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "        special_char = \"+=`@_!#$%^&*()<>?/\\|}{~:;.[],1234567890‘’'\" + '\"“”●'\n",
    "        out_list = [''.join(x for x in string if not x in special_char) for string in word_tokens_no_stopwords]\n",
    "        # print('List after removal of special characters:', out_list)\n",
    "\n",
    "        while '' in out_list:\n",
    "            out_list.remove('')\n",
    "        data_kata.append(out_list)\n",
    "    return data_kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Script diatas digunakan untuk pemrosesan Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_kata = stopping_word(contents)\n",
    "data['stop_kata'] = stop_kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Penerapan stopword pada data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [abstrak, penelitian, rumusan, pelaporan, biay...\n",
       "1     [bauran, eceran, salah, langkah, pemasaran, ke...\n",
       "2     [tujuan, penelitian, pengaruh, celebrity, endo...\n",
       "3     [ali, rahbini, pengaruh, harga, kualitas, pela...\n",
       "4     [tujuan, penelitian, pengaruh, variabel, retai...\n",
       "5     [abstrak, tujuan, penelitian, pengaruh, variab...\n",
       "6     [abstrak, penelitian, bertujuan, mengukur, efe...\n",
       "7     [abstrak, tujuan, penelitian, mendeskripsikan,...\n",
       "8     [tujuan, penelitian, mengidentifikasi, variabe...\n",
       "9     [objek, penelitian, pembelian, produk, xl, kec...\n",
       "10    [pln, badan, usaha, milik, negara, bergerak, b...\n",
       "11    [intention, research, know, influence, locatio...\n",
       "12    [kenaikan, harga, menyebabkan, permintaan, pem...\n",
       "13    [pengaruh, bundling, strategy, keputusan, pemb...\n",
       "14    [tujuan, penelitian, tingkat, kebangkrutan, pe...\n",
       "15    [abstrak, tujuan, penelitian, pengaruh, variab...\n",
       "16    [tujuan, penlitian, variabel, iklan, berdasark...\n",
       "17    [abstrak, tujuan, penelitian, harga, kualitas,...\n",
       "18    [abstrak, tujuan, penelitian, menganalisis, at...\n",
       "19    [ulfiyatun, mutohharoh, analisis, faktor-fakto...\n",
       "20    [pendekatan, penelitian, penelitian, pendekata...\n",
       "21    [tujuan, penelitian, pengaruh, variabel, relat...\n",
       "22    [diana, agustini, dewi, analisis, kinerja, keu...\n",
       "23    [tujuan, penelitian, pengaruh, variabel, self,...\n",
       "24    [muhammad, sholeh, pengaruh, iklan, televisi, ...\n",
       "25    [abstrak, tujuan, penelitian, variabel, kompen...\n",
       "26    [abstrak, penelitian, bertujuan, meneliti, pen...\n",
       "27    [abtrak, uswatun, khasanah, pengaruh, etos, ke...\n",
       "28    [munculnya, asumsi, lahirnya, budaya, mengemis...\n",
       "29    [abstrak, penelitian, bertujuan, pengaruh, fak...\n",
       "30    [keputusan, investasi, berhubungan, keuntungan...\n",
       "31    [penelitian, bertujuan, pengaruh, rekrutmen, p...\n",
       "32    [abstrak, hening, ary, putra, pengaruh, iklan,...\n",
       "33    [habibah, pengaruh, ekuitas, merek, keputusan,...\n",
       "34    [atribut, produk, pandangan, gambaran, produk,...\n",
       "35    [tujuan, penelitian, pengaruh, variabel, perse...\n",
       "36    [kusniyah, analisis, volume, perdagangan, saha...\n",
       "37    [muzanni, peranan, manajemen, piutang, tertaha...\n",
       "38    [abstrak, ike, miranti, pengaruh, strategi, pr...\n",
       "39    [anissa, novianti, pengaruh, atribut, produk, ...\n",
       "40    [abstrak, tujuan, penelitian, variabel, harga,...\n",
       "41    [abstrak, tujuan, penelitian, pengaruh, elemen...\n",
       "42    [abstrak, harga, merek, salah, langkah, diperh...\n",
       "43    [menjalani, pekerjaan, mencampur, adukkan, per...\n",
       "44    [abstrak, penelitian, bertujuan, pengaruh, uns...\n",
       "45    [tujuan, penelitian, marketing, mix, produk, h...\n",
       "46    [abstrak, tujuan, penelitian, mengidentifikasi...\n",
       "47    [abstrak, tujuan, penelitian, pengaruh, perila...\n",
       "48    [abstrak, tujuan, penelitian, pengaruh, bauran...\n",
       "49    [abstrak, tujuan, penelitian, pengaruh, pesan,...\n",
       "Name: stop_kata, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stop_kata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">hasil stopword berupa list tiap dokumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <li> Term Frequency — Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF adalah suatu metode algoritma untuk menghitung bobot setiap kata di setiap dokumen dalam korpus. Metode ini juga terkenal efisien, mudah dan memiliki hasil yang akurat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inti utama dari algoritma ini adalah melakukan perhitungan nilai TF dan nilai IDF dari sebuah setiap kata kunci terhadap masing-masing dokumen. Nilai TF dihitung dengan rumus TF = jumlah frekuensi kata terpilih / jumlah kata dan nilai IDF dihitung dengan rumus IDF = log(jumlah dokumen / jumlah frekuensi kata terpilih). Selanjutnya kedua hasil ini akan dikalikan sehingga menghasilkan TF-IDF. <br><br> TF-IDF dihitung dengan menggunakan persamaan seperti berikut.\n",
    "\n",
    "$$\n",
    "W_{i, j}=\\frac{n_{i, j}}{\\sum_{j=1}^{p} n_{j, i}} \\log _{2} \\frac{D}{d_{j}}\n",
    "$$\n",
    "\n",
    "Keterangan:\n",
    "\n",
    "$\n",
    "{W_{i, j}}\\quad\\quad\\>: \\text { pembobotan tf-idf untuk term ke-j pada dokumen ke-i } \\\\\n",
    "{n_{i, j}}\\quad\\quad\\>\\>: \\text { jumlah kemunculan term ke-j pada dokumen ke-i }\\\\\n",
    "{p} \\quad\\quad\\quad\\>\\>: \\text { banyaknya term yang terbentuk }\\\\\n",
    "{\\sum_{j=1}^{p} n_{j, i}}: \\text { jumlah kemunculan seluruh term pada dokumen ke-i }\\\\\n",
    "{d_{j}} \\quad\\quad\\quad: \\text { banyaknya dokumen yang mengandung term ke-j }\\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Mempersiapkan data yang sudah di stopword agar sesuai dengan format inputan dari salah satu library scikit-learn, yakni TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     abstrak penelitian rumusan pelaporan biaya kua...\n",
       "1     bauran eceran salah langkah pemasaran keberhas...\n",
       "2     tujuan penelitian pengaruh celebrity endorser ...\n",
       "3     ali rahbini pengaruh harga kualitas pelayanan ...\n",
       "4     tujuan penelitian pengaruh variabel retailing ...\n",
       "5     abstrak tujuan penelitian pengaruh variabel cu...\n",
       "6     abstrak penelitian bertujuan mengukur efektivi...\n",
       "7     abstrak tujuan penelitian mendeskripsikan inov...\n",
       "8     tujuan penelitian mengidentifikasi variabel-va...\n",
       "9     objek penelitian pembelian produk xl kecamatan...\n",
       "10    pln badan usaha milik negara bergerak bidang p...\n",
       "11    intention research know influence location eff...\n",
       "12    kenaikan harga menyebabkan permintaan pembelia...\n",
       "13    pengaruh bundling strategy keputusan pembelian...\n",
       "14    tujuan penelitian tingkat kebangkrutan perusah...\n",
       "15    abstrak tujuan penelitian pengaruh variabel ku...\n",
       "16    tujuan penlitian variabel iklan berdasarkan ko...\n",
       "17    abstrak tujuan penelitian harga kualitas produ...\n",
       "18    abstrak tujuan penelitian menganalisis atribut...\n",
       "19    ulfiyatun mutohharoh analisis faktor-faktor me...\n",
       "20    pendekatan penelitian penelitian pendekatan ku...\n",
       "21    tujuan penelitian pengaruh variabel relationsh...\n",
       "22    diana agustini dewi analisis kinerja keuangan ...\n",
       "23    tujuan penelitian pengaruh variabel self effic...\n",
       "24    muhammad sholeh pengaruh iklan televisi keputu...\n",
       "25    abstrak tujuan penelitian variabel kompensasi ...\n",
       "26    abstrak penelitian bertujuan meneliti pendidik...\n",
       "27    abtrak uswatun khasanah pengaruh etos kerja pr...\n",
       "28    munculnya asumsi lahirnya budaya mengemis dise...\n",
       "29    abstrak penelitian bertujuan pengaruh faktor-f...\n",
       "30    keputusan investasi berhubungan keuntungan ris...\n",
       "31    penelitian bertujuan pengaruh rekrutmen pengem...\n",
       "32    abstrak hening ary putra pengaruh iklan online...\n",
       "33    habibah pengaruh ekuitas merek keputusan pembe...\n",
       "34    atribut produk pandangan gambaran produk deale...\n",
       "35    tujuan penelitian pengaruh variabel persepsi n...\n",
       "36    kusniyah analisis volume perdagangan saham ret...\n",
       "37    muzanni peranan manajemen piutang tertahadap r...\n",
       "38    abstrak ike miranti pengaruh strategi promosi ...\n",
       "39    anissa novianti pengaruh atribut produk keputu...\n",
       "40    abstrak tujuan penelitian variabel harga kuali...\n",
       "41    abstrak tujuan penelitian pengaruh elemen-elem...\n",
       "42    abstrak harga merek salah langkah diperhatikan...\n",
       "43    menjalani pekerjaan mencampur adukkan permasal...\n",
       "44    abstrak penelitian bertujuan pengaruh unsur - ...\n",
       "45    tujuan penelitian marketing mix produk harga p...\n",
       "46    abstrak tujuan penelitian mengidentifikasi var...\n",
       "47    abstrak tujuan penelitian pengaruh perilaku ko...\n",
       "48    abstrak tujuan penelitian pengaruh bauran pema...\n",
       "49    abstrak tujuan penelitian pengaruh pesan iklan...\n",
       "Name: stop_kata_join, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stop_kata_join'] = [' '.join(map(str, l)) for l in data['stop_kata']]\n",
    "data['stop_kata_join']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Menggunakan library CountVectorizer untuk mendapatkan value dari setiap kata yang muncul didalam sebuah dokumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bag = vectorizer.fit_transform(data['stop_kata_join'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 699)\t4\n",
      "  (0, 858)\t1\n",
      "  (0, 681)\t5\n",
      "  (0, 109)\t6\n",
      "  (0, 465)\t6\n",
      "  (0, 546)\t1\n",
      "  (0, 851)\t4\n",
      "  (0, 783)\t5\n",
      "  (0, 128)\t5\n",
      "  (0, 146)\t2\n",
      "  (0, 375)\t2\n",
      "  (0, 345)\t2\n",
      "  (0, 871)\t2\n",
      "  (0, 709)\t2\n",
      "  (0, 987)\t2\n",
      "  (0, 789)\t5\n",
      "  (0, 105)\t1\n",
      "  (0, 758)\t3\n",
      "  (0, 598)\t1\n",
      "  (0, 163)\t1\n",
      "  (0, 567)\t1\n",
      "  (0, 262)\t1\n",
      "  (0, 555)\t1\n",
      "  (0, 1024)\t1\n",
      "  :\t:\n",
      "  (49, 49)\t1\n",
      "  (49, 435)\t1\n",
      "  (49, 32)\t2\n",
      "  (49, 827)\t1\n",
      "  (49, 497)\t1\n",
      "  (49, 90)\t1\n",
      "  (49, 469)\t1\n",
      "  (49, 602)\t6\n",
      "  (49, 219)\t2\n",
      "  (49, 322)\t5\n",
      "  (49, 759)\t18\n",
      "  (49, 941)\t5\n",
      "  (49, 106)\t1\n",
      "  (49, 931)\t3\n",
      "  (49, 961)\t5\n",
      "  (49, 350)\t4\n",
      "  (49, 277)\t3\n",
      "  (49, 936)\t3\n",
      "  (49, 669)\t5\n",
      "  (49, 356)\t5\n",
      "  (49, 991)\t5\n",
      "  (49, 36)\t5\n",
      "  (49, 890)\t5\n",
      "  (49, 625)\t5\n",
      "  (49, 520)\t5 \n",
      "\n",
      "(50, 1040)\n"
     ]
    }
   ],
   "source": [
    "print(bag, '\\n')\n",
    "print(bag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variabel \"bag\" berisi total kemunculan kata dalam corpus yang muncul dalam setiap dokumen.  Jadi dari variabel ini dapat diketahui total kata yang diperoleh dari 10 dokumen adalah sebanyak 339 kata, yang dimana setiap dokumen akan menghitung term frequency-nya masing-masing dari daftar kata didalam corpus 10 data ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstrak': 0, 'penelitian': 699, 'rumusan': 858, 'pelaporan': 681, 'biaya': 109, 'kualitas': 465, 'meminimalkan': 546, 'risiko': 851, 'produk': 783, 'cacat': 128, 'cv': 146, 'kapuas': 375, 'inti': 345, 'sarana': 871, 'pengaruh': 709, 'tingkat': 987, 'profitabilitas': 789, 'bertujuan': 105, 'perusahaan': 758, 'metode': 598, 'deskriptif': 163, 'menggambarkan': 567, 'fenomena': 262, 'mendeskripsikan': 555, 'variabel': 1024, 'berasal': 81, 'data': 152, 'hasil': 305, 'periodik': 744, 'terperinci': 978, 'berpengaruh': 99, 'peningkatan': 721, 'mengurangi': 579, 'berkurang': 94, 'penjualan': 722, 'langsung': 483, 'meningkatnya': 583, 'kunci': 471, 'bauran': 70, 'eceran': 229, 'salah': 863, 'langkah': 482, 'pemasaran': 685, 'keberhasilan': 387, 'bergerak': 91, 'bidang': 110, 'produksi': 784, 'barang': 68, 'jasaindah': 360, 'swalayan': 949, 'bangkalan': 60, 'bisnis': 114, 'jual': 367, 'beli': 78, 'memperhatikan': 548, 'perilaku': 741, 'konsumen': 452, 'mengambil': 563, 'keputusan': 412, 'teori': 964, 'berman': 97, 'evans': 252, 'foster': 278, 'lokasi': 501, 'pelayanan': 683, 'harga': 303, 'suasana': 933, 'promosi': 791, 'tujuan': 1000, 'simultan': 899, 'pembelian': 687, 'studi': 932, 'indah': 324, 'pendekatan': 694, 'kuantitatif': 467, 'teknik': 958, 'pengambilan': 708, 'sampel': 865, 'purposive': 806, 'sampling': 868, 'respondenteknik': 838, 'pengumpulan': 720, 'wawancara': 1033, 'kepustakaan': 411, 'kuesioner': 470, 'skala': 905, 'likert': 493, 'mengukur': 577, 'respondenuntuk': 840, 'menguji': 576, 'instrumen': 338, 'uji': 1008, 'validitas': 1023, 'reliabilitas': 830, 'asumsi': 49, 'klasiksedangkan': 435, 'analisis': 32, 'regresi': 827, 'linier': 497, 'berganda': 90, 'namun': 629, 'parsial': 668, 'bangakalan': 59, 'pemebelian': 688, 'kuci': 469, 'toko': 990, 'karyawan': 379, 'celebrity': 131, 'endorser': 243, 'iwan': 352, 'fals': 260, 'minat': 602, 'top': 993, 'coffee': 137, 'masyarakat': 528, 'sumur': 938, 'kembang': 404, 'kelurahan': 401, 'pejagan': 676, 'kecamatan': 391, 'kabupaten': 371, 'survey': 945, 'populasi': 766, 'menngunakan': 586, 'aksidental': 18, 'responden': 837, 'desember': 161, 'lapang': 484, 'membagikan': 538, 'riset': 850, 'perpustakaan': 750, 'pengolahan': 717, 'bantuan': 66, 'erangkat': 247, 'lunak': 505, 'spss': 918, 'versi': 1029, 'windows': 1036, 'bebas': 72, 'trustworthiness': 997, 'expertise': 256, 'attractiveness': 54, 'respect': 836, 'similarity': 896, 'mempengaruhi': 547, 'terikat': 973, 'minet': 604, 'membuktikan': 542, 'signifikan': 893, 'disimpulkan': 201, 'miant': 599, 'ali': 25, 'rahbini': 814, 'kepuasan': 410, 'berbelanja': 85, 'tom': 992, 'jerry': 364, 'dibawah': 177, 'bimbingan': 112, 'pribanus': 782, 'wantara': 1032, 'nirma': 638, 'kurriwati': 473, 'terkumpul': 975, 'alat': 24, 'bantu': 65, 'software': 909, 'pengujian': 719, 'hipotesis': 312, 'diperoleh': 195, 'kehandalan': 396, 'daya': 153, 'tanggap': 956, 'jaminan': 355, 'empati': 240, 'bukti': 122, 'fisik': 269, 'dominan': 219, 'keandalan': 383, 'retailing': 845, 'mix': 610, 'merchandise': 595, 'atmosfer': 51, 'gerai': 288, 'retailimg': 844, 'idola': 319, 'mart': 524, 'kwanyar': 475, 'berlandaskan': 95, 'filsafat': 265, 'positivisme': 772, 'ditetapkan': 211, 'klasik': 434, 'memakai': 535, 'berdasarkan': 88, 'nilai': 637, 'adjusted': 7, 'square': 919, 'besarnya': 107, 'sisanya': 901, 'dipengaruhi': 193, 'diteliti': 207, 'current': 144, 'ratio': 821, 'return': 846, 'equity': 246, 'firm': 268, 'size': 904, 'leverage': 491, 'business': 126, 'risk': 852, 'kebijakan': 389, 'deviden': 167, 'manufaktur': 518, 'terdaftar': 969, 'bursa': 124, 'efek': 231, 'indonesia': 333, 'periode': 743, 'businees': 125, 'dividend': 215, 'payout': 674, 'efektivitas': 232, 'iklan': 322, 'consumer': 142, 'decision': 156, 'model': 613, 'cdm': 130, 'mahasiswa': 509, 'universitas': 1014, 'trunojoyo': 996, 'madura': 507, 'orang': 655, 'jalur': 354, 'path': 672, 'analysis': 33, 'pesan': 759, 'pengenalan': 713, 'merek': 596, 'keyakinan': 426, 'sikap': 895, 'niat': 636, 'nyata': 646, 'inovasi': 337, 'keunggulan': 424, 'bersaing': 102, 'kinerja': 430, 'diterapkannya': 209, 'optik': 653, 'reza': 848, 'lamongan': 480, 'kualitatif': 466, 'fenomenologi': 263, 'observasi': 648, 'penggunaan': 715, 'dokumen': 218, 'reduction': 826, 'display': 204, 'conclusion': 140, 'drawing': 223, 'verification': 1028, 'meningkatkan': 582, 'menerapkan': 559, 'volume': 1030, 'omzet': 650, 'meningkat': 581, 'terbukti': 968, 'mengalami': 562, 'ditawarkannya': 206, 'perbaikan': 732, 'pangsa': 667, 'pasarnya': 670, 'meluas': 534, 'daerah': 147, 'jawa': 361, 'timur': 985, 'mengidentifikasi': 571, 'ulang': 1010, 'nasabah': 630, 'bri': 120, 'layanan': 487, 'internet': 344, 'banking': 64, 'dimana': 188, 'kota': 458, 'diambil': 170, 'persepsi': 752, 'manfaat': 517, 'kemudahan': 405, 'keamanan': 382, 'ketersediaan': 421, 'fitur': 270, 'positif': 771, 'kecuali': 393, 'objek': 647, 'xl': 1037, 'meguji': 532, 'berdasar': 87, 'sistematis': 903, 'distribusi': 205, 'bangkalansecara': 61, 'strategi': 926, 'segi': 874, 'pln': 764, 'badan': 56, 'usaha': 1017, 'milik': 601, 'negara': 632, 'penyediaan': 727, 'listrik': 499, 'nasional': 631, 'mengelola': 565, 'bisnisnya': 115, 'praktek': 775, 'paktek': 664, 'terbaik': 966, 'mengoptimalisasikan': 575, 'sumbr': 937, 'manusia': 519, 'dimiliki': 190, 'proses': 794, 'pengembangan': 711, 'karir': 376, 'semangat': 881, 'kerja': 413, 'cabang': 127, 'bersifat': 103, 'respondenuji': 839, 'koefisien': 439, 'determinasi': 165, 'prestasi': 780, 'kesetiaan': 418, 'orgnisasional': 657, 'mentor': 588, 'sponsor': 917, 'kesempatan': 417, 'tumbuh': 1001, 'memiliki': 545, 'diatas': 174, 'kuat': 468, 'intention': 340, 'research': 834, 'know': 438, 'influence': 334, 'location': 500, 'effort': 234, 'service': 883, 'quality': 811, 'terhadap': 970, 'purchasing': 803, 'also': 27, 'variable': 1025, 'whichsuch': 1034, 'bigger': 111, 'ppengaruh': 774, 'home': 315, 'eat': 228, 'depot': 158, 'soto': 913, 'glorious': 292, 'asih': 44, 'use': 1018, 'quantitative': 812, 'method': 597, 'approach': 40, 'population': 768, 'entireall': 245, 'doingconducting': 217, 'used': 1019, 'accidental': 2, 'hence': 310, 'get': 289, 'responder': 841, 'collecting': 138, 'library': 492, 'result': 843, 'mention': 587, 'tied': 983, 'test': 982, 'prove': 795, 'free': 279, 'consisting': 141, 'together': 989, 'concluded': 139, 'keywords': 427, 'purchase': 802, 'kenaikan': 406, 'menyebabkan': 592, 'permintaan': 749, 'saham': 860, 'penurunan': 725, 'fluk': 272, 'tuatif': 998, 'menghindari': 570, 'kondisi': 448, 'menurunkan': 590, 'kisaran': 432, 'menarik': 553, 'investor': 348, 'membeli': 540, 'pemecahan': 689, 'stock': 925, 'split': 916, 'dasarnya': 151, 'permasalahan': 748, 'berbeda': 84, 'beda': 74, 'bei': 76, 'paired': 661, 'sample': 866, 'pengamatan': 706, 'penetuan': 704, 'perbedaan': 733, 'rata': 820, 'tva': 1005, 'perdagangan': 735, 'pergerakan': 737, 'bundling': 123, 'strategy': 927, 'restoran': 842, 'quick': 813, 'chicken': 133, 'raya': 822, 'dukuh': 226, 'kupang': 472, 'surabayadibimbing': 942, 'yustina': 1039, 'chrismardani': 134, 'focus': 274, 'form': 276, 'manakah': 516, 'makanan': 511, 'cepat': 132, 'saji': 861, 'surabaya': 941, 'bentuk': 80, 'paketan': 663, 'surabayametode': 943, 'mebagikan': 530, 'mengunakan': 578, 'perangkat': 730, 'menunjukan': 589, 'kebangkrutan': 384, 'minuman': 606, 'bangkrut': 62, 'altman': 29, 'memperoleh': 549, 'peringatan': 742, 'tanda': 954, 'diskriptif': 203, 'peneliti': 698, 'dijadikan': 185, 'menghasilkan': 569, 'score': 872, 'kritis': 464, 'sehat': 876, 'profesionalisme': 788, 'keterampilan': 420, 'aksesibilitas': 17, 'fleksibilitas': 271, 'kepercayaan': 409, 'reputasi': 833, 'kredibilitas': 461, 'recovery': 825, 'serviscape': 884, 'pasien': 671, 'rumah': 857, 'sakit': 862, 'terpadu': 976, 'servisecape': 885, 'penlitian': 723, 'konsep': 451, 'aida': 13, 'helm': 309, 'ink': 336, 'berusaha': 106, 'attention': 53, 'interest': 342, 'desire': 162, 'action': 4, 'deterjen': 164, 'rinso': 849, 'anti': 38, 'noda': 639, 'berdomisili': 89, 'desa': 159, 'telang': 960, 'menganalisis': 564, 'atribut': 52, 'kepentingan': 408, 'pengguna': 714, 'sepeda': 882, 'motor': 619, 'jembatan': 362, 'suramadu': 944, 'diagram': 169, 'kartesius': 377, 'importance': 323, 'performance': 736, 'enam': 242, 'fokus': 275, 'utama': 1021, 'ketidak': 422, 'puasan': 799, 'lampu': 481, 'penerangan': 701, 'terpasang': 977, 'menyala': 591, 'malam': 514, 'petugas': 761, 'jasa': 359, 'marga': 522, 'berpenampilan': 98, 'rapi': 817, 'jalan': 353, 'mulus': 624, 'berlubang': 96, 'tiket': 984, 'teliti': 962, 'uang': 1006, 'kembalian': 403, 'pt': 797, 'asuransi': 50, 'kecelakaan': 392, 'patroli': 673, 'sungguh': 939, 'mogok': 616, 'ban': 58, 'bocor': 118, 'dll': 216, 'ulfiyatun': 1011, 'mutohharoh': 627, 'faktor': 258, 'menentukan': 557, 'preferensi': 778, 'belanja': 77, 'online': 651, 'fashion': 261, 'mahasiwa': 510, 'fakultas': 259, 'ekonomi': 236, 'journal': 366, 'economics': 230, 'program': 790, 'manajemen': 515, 'drs': 224, 'mohamad': 617, 'tambrin': 952, 'mm': 611, 'crismardani': 143, 'ssi': 920, 'sistem': 902, 'informasi': 335, 'global': 291, 'berbasis': 83, 'komputer': 444, 'perlahan': 746, 'lahan': 477, 'menggeser': 568, 'budaya': 121, 'konvensional': 453, 'praktis': 776, 'modern': 614, 'dirilis': 198, 'detikcom': 166, 'dibeli': 178, 'dipertimbangkan': 196, 'menetukan': 560, 'berketergantungan': 93, 'interdependent': 341, 'jenis': 363, 'statistic': 922, 'konfirmatori': 449, 'didapatkan': 182, 'kmo': 437, 'item': 351, 'rendah': 831, 'klasifikasi': 433, 'miserable': 609, 'statistik': 924, 'ukuran': 1009, 'kecukuperatan': 394, 'hubungan': 317, 'layak': 486, 'kesimpulan': 419, 'alternatif': 28, 'liquid': 498, 'penarikan': 691, 'purpossive': 807, 'dianalisis': 172, 'statistical': 923, 'solution': 910, 'duga': 225, 'rasio': 818, 'likuiditas': 494, 'struktur': 931, 'modal': 612, 'debt': 155, 'roe': 854, 'lq': 504, 'relationship': 829, 'marketing': 523, 'keuntungan': 425, 'komitmen': 441, 'komunikasi': 446, 'kebenaran': 385, 'loyalitas': 502, 'adira': 6, 'finance': 266, 'wilayah': 1035, 'barat': 69, 'negatif': 633, 'diana': 171, 'agustini': 12, 'dewi': 168, 'keuangan': 423, 'akuisisi': 23, 'melakuukan': 533, 'jurusan': 369, 'dipilih': 197, 'didasarkan': 183, 'kriteria': 462, 'tersedia': 979, 'laporan': 485, 'aktivitas': 22, 'pengakuisisi': 705, 'pengambil': 707, 'alih': 26, 'asset': 46, 'mengakuisisi': 561, 'anak': 31, 'diukur': 213, 'total': 994, 'turnover': 1004, 'investmen': 347, 'earning': 227, 'sharekelima': 887, 'dianalisisi': 173, 'samples': 867, 'self': 878, 'efficacy': 233, 'magnitude': 508, 'generality': 287, 'strength': 928, 'akademik': 15, 'berprestasi': 100, 'mengikuti': 572, 'mawapres': 529, 'diterima': 210, 'temuan': 963, 'teridiri': 972, 'r²': 859, 'muhammad': 622, 'sholeh': 888, 'televisi': 961, 'kartu': 378, 'seluler': 879, 'geger': 286, 'bambang': 57, 'setiyo': 886, 'pambudi': 665, 'suyono': 948, 'msm': 621, 'isi': 350, 'format': 277, 'sumber': 936, 'kompensasi': 442, 'finansial': 267, 'nonfinansial': 641, 'fhitung': 264, 'pos': 770, 'persero': 753, 'kantor': 374, 'meneliti': 556, 'pendidikan': 695, 'pelatihan': 682, 'rangka': 816, 'produktivitas': 786, 'meniliti': 580, 'perubahan': 756, 'disebabkan': 200, 'masuk': 527, 'kebenarannya': 386, 'beta': 108, 'abtrak': 1, 'uswatun': 1020, 'khasanah': 428, 'etos': 250, 'presatasi': 779, 'ptpln': 798, 'diatribusi': 175, 'area': 41, 'mojokerto': 618, 'dibagikan': 176, 'semanagt': 880, 'disiplin': 202, 'munculnya': 626, 'lahirnya': 478, 'mengemis': 566, 'memilih': 543, 'profesi': 787, 'pengemis': 712, 'lingkungan': 495, 'keluarga': 400, 'periaku': 739, 'kebiasaan': 388, 'kehidupan': 397, 'sehari': 875, 'hari': 304, 'kamal': 372, 'kab': 370, 'memprihatinkan': 550, 'indikator': 329, 'etnografis': 249, 'sosialisasi': 912, 'peran': 728, 'berprofesi': 101, 'modus': 615, 'operandi': 652, 'jaringan': 358, 'indicator': 327, 'behavioral': 75, 'sociology': 908, 'menerangkan': 558, 'tingkah': 986, 'laku': 479, 'akibatnya': 16, 'teory': 965, 'exchange': 254, 'social': 907, 'kekecewaan': 398, 'bersumber': 104, 'adnya': 8, 'dorongan': 220, 'sosial': 911, 'stres': 929, 'terhdap': 971, 'dosen': 221, 'stressor': 930, 'individu': 330, 'kelompok': 399, 'organisasi': 656, 'katakunci': 380, 'investasi': 346, 'berhubungan': 92, 'rasional': 819, 'menginvestasikan': 573, 'dananya': 149, 'efisien': 235, 'minimal': 605, 'aktif': 19, 'frekuensi': 280, 'membagi': 537, 'dividen': 214, 'membentuk': 541, 'portofolio': 769, 'optimal': 654, 'kandidat': 373, 'non': 640, 'cut': 145, 'off': 649, 'point': 765, 'dibentuk': 179, 'excess': 253, 'returns': 847, 'erb': 248, 'ci': 135, 'perhitungan': 738, 'komposisi': 443, 'proporsi': 792, 'dana': 148, 'adaro': 5, 'energy': 244, 'tbk': 957, 'gudang': 298, 'garam': 284, 'hm': 314, 'sampoerna': 869, 'astra': 48, 'otopart': 659, 'multi': 623, 'bintang': 113, 'agro': 10, 'lestari': 490, 'goodyear': 294, 'indika': 328, 'united': 1013, 'tractors': 995, 'pabrik': 660, 'kertas': 414, 'tjiwi': 988, 'kimia': 429, 'indofood': 331, 'sukses': 934, 'makmur': 512, 'international': 343, 'bank': 63, 'indeks': 325, 'tunggal': 1003, 'benar': 79, 'aktiva': 21, 'expected': 255, 'rekrutmen': 828, 'pusat': 809, 'gresik': 297, 'cipta': 136, 'sejahtera': 877, 'hening': 311, 'ary': 43, 'putra': 810, 'media': 531, 'facebook': 257, 'pakaian': 662, 'pemimbing': 690, 'se': 873, 'klik': 436, 'menyebarkan': 593, 'vairabel': 1022, 'habibah': 299, 'ekuitas': 237, 'notebook': 642, 'acer': 3, 'dibuktikan': 181, 'penguasaan': 718, 'hamper': 301, 'pasar': 669, 'dasar': 150, 'kenyataan': 407, 'penelitiannya': 700, 'dilaksanakan': 186, 'penelitan': 697, 'bebasnya': 73, 'kesadaran': 415, 'asosiasi': 45, 'terikatnya': 974, 'instrument': 339, 'realibilitas': 824, 'pandangan': 666, 'gambaran': 282, 'dealer': 154, 'surya': 946, 'agung': 11, 'resmi': 835, 'honda': 316, 'kotler': 459, 'armstrong': 42, 'gaya': 285, 'desain': 160, 'memutuskan': 552, 'supra': 940, 'mempunyah': 551, 'emosional': 239, 'pelanggan': 680, 'variebel': 1027, 'memilik': 544, 'terbesar': 967, 'yamaha': 1038, 'new': 635, 'jupiter': 368, 'liniear': 496, 'hasilnya': 306, 'diolah': 192, 'aplikasi': 39, 'kusniyah': 474, 'go': 293, 'public': 800, 'hj': 313, 'evaliati': 251, 'amaniyah': 30, 'prasetyo': 777, 'nugroho': 644, 'spi': 915, 'statis': 921, 'fluktuatif': 273, 'diharapkan': 184, 'empiris': 241, 'aktifitas': 20, 'muzanni': 628, 'peranan': 729, 'piutang': 763, 'tertahadap': 980, 'rentabilitas': 832, 'koperasi': 454, 'syariah': 951, 'bmt': 117, 'ugt': 1007, 'sidogiri': 891, 'pembantu': 686, 'kpri': 460, 'kopergu': 455, 'purnamawati': 804, 'msi': 620, 'lembaga': 488, 'pendapatan': 693, 'pinjaman': 762, 'pendanaan': 692, 'anggota': 35, 'otomatis': 658, 'tertanam': 981, 'potensi': 773, 'penerapan': 702, 'pengelolaan': 710, 'diterapkan': 208, 'kriterian': 463, 'pertumbuhan': 755, 'perputaran': 751, 'kategori': 381, 'perkembangan': 745, 'ike': 321, 'miranti': 608, 'maan': 506, 'ghodaqo': 290, 'siddiq': 889, 'jombang': 365, 'dibimbing': 180, 'sp': 914, 'periklanan': 740, 'publisitas': 801, 'personal': 754, 'menitikberatkan': 584, 'air': 14, 'mineral': 603, 'kemasan': 402, 'purprosive': 808, 'maret': 521, 'reabilitas': 823, 'teknis': 959, 'memakaiuji': 536, 'anissa': 37, 'novianti': 643, 'minyak': 607, 'goreng': 295, 'sania': 870, 'ibu': 318, 'perumahan': 757, 'graha': 296, 'permai': 747, 'dr': 222, 'nurita': 645, 'andriani': 34, 'ir': 349, 'hadi': 300, 'purnomo': 805, 'label': 476, 'simple': 897, 'random': 815, 'martabak': 525, 'hawaii': 307, 'elemen': 238, 'brand': 119, 'awareness': 55, 'assocations': 47, 'kesan': 416, 'perceived': 734, 'loyalty': 503, 'handphone': 302, 'blackberry': 116, 'diperhatikan': 194, 'kopontren': 456, 'tanah': 953, 'merah': 594, 'menjalani': 585, 'pekerjaan': 677, 'mencampur': 554, 'adukkan': 9, 'dirumah': 199, 'tangga': 955, 'membawa': 539, 'kedalam': 395, 'sulit': 935, 'penuh': 724, 'beban': 71, 'berat': 82, 'berdampak': 86, 'pekerjaannya': 678, 'tugas': 999, 'maksimal': 513, 'dilakukannya': 187, 'jangka': 357, 'lembur': 489, 'konflik': 450, 'ganda': 283, 'perawat': 731, 'wanita': 1031, 'rs': 856, 'syamrabu': 950, 'kinerjanya': 431, 'unsur': 1015, 'pengirim': 716, 'komunikator': 447, 'penerima': 703, 'komunikan': 445, 'umpan': 1012, 'produktifitas': 785, 'pegawai': 675, 'negeri': 634, 'sipil': 900, 'dinas': 191, 'pendidikian': 696, 'proporsional': 793, 'ftabel': 281, 'signifikansi': 894, 'dimasukkan': 189, 'varibel': 1026, 'kominkator': 440, 'sigifikan': 892, 'upaya': 1016, 'rokok': 855, 'mild': 600, 'socah': 906, 'penyedap': 726, 'masako': 526, 'populasinya': 767, 'robatal': 853, 'sampang': 864, 'mengkonsumsi': 574, 'pelabelan': 679, 'pelengkap': 684, 'independen': 326, 'dependen': 157, 'simpulan': 898, 'kebudayaan': 390, 'pribadi': 781, 'psikologis': 796, 'susu': 947, 'cair': 129, 'indomilk': 332, 'petis': 760, 'ikan': 320, 'tuna': 1002, 'hdiya': 308, 'banyuanyar': 67, 'kosumen': 457, 'ditribusi': 212, 'jamu': 356, 'tolak': 991, 'angin': 36, 'sido': 890, 'muncul': 625, 'manyar': 520}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diatas ini merupakan daftar kata didalam corpus yang berjumlah 339 data kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Pemrosesan TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(use_idf=True,norm='l2',smooth_idf=True)\n",
    "vect_abstrak=tfidf.fit_transform(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1024)\t0.020900295374455924\n",
      "  (0, 987)\t0.10991580583903934\n",
      "  (0, 978)\t0.14837195571811498\n",
      "  (0, 871)\t0.14837195571811498\n",
      "  (0, 858)\t0.07418597785905749\n",
      "  (0, 851)\t0.2683578700111031\n",
      "  (0, 789)\t0.3354473375138789\n",
      "  (0, 783)\t0.1786491398999093\n",
      "  (0, 758)\t0.13304767301837103\n",
      "  (0, 744)\t0.07418597785905749\n",
      "  (0, 722)\t0.05814892180151073\n",
      "  (0, 721)\t0.13417893500555156\n",
      "  (0, 709)\t0.04264410858027216\n",
      "  (0, 699)\t0.0713949463098071\n",
      "  (0, 681)\t0.3709298892952874\n",
      "  (0, 598)\t0.03143965842604761\n",
      "  (0, 583)\t0.07418597785905749\n",
      "  (0, 579)\t0.07418597785905749\n",
      "  (0, 567)\t0.07418597785905749\n",
      "  (0, 555)\t0.06708946750277578\n",
      "  (0, 546)\t0.07418597785905749\n",
      "  (0, 483)\t0.05495790291951967\n",
      "  (0, 471)\t0.02311872249372509\n",
      "  (0, 465)\t0.26609534603674206\n",
      "  (0, 375)\t0.14837195571811498\n",
      "  :\t:\n",
      "  (49, 520)\t0.21944521826598395\n",
      "  (49, 497)\t0.016563143929987218\n",
      "  (49, 493)\t0.02533641918581737\n",
      "  (49, 470)\t0.021729906476264584\n",
      "  (49, 469)\t0.03671190879642282\n",
      "  (49, 467)\t0.019541924032929706\n",
      "  (49, 452)\t0.10569032215992946\n",
      "  (49, 435)\t0.03440138744523189\n",
      "  (49, 411)\t0.029534773939648852\n",
      "  (49, 356)\t0.21944521826598395\n",
      "  (49, 350)\t0.15876275559746125\n",
      "  (49, 338)\t0.02533641918581737\n",
      "  (49, 322)\t0.1625677702129567\n",
      "  (49, 305)\t0.011883101541675076\n",
      "  (49, 277)\t0.11907206669809595\n",
      "  (49, 219)\t0.040094235463367905\n",
      "  (49, 152)\t0.030361008452201816\n",
      "  (49, 106)\t0.03091741364353516\n",
      "  (49, 99)\t0.02792185915042384\n",
      "  (49, 90)\t0.01584876297785247\n",
      "  (49, 78)\t0.19508132425554803\n",
      "  (49, 49)\t0.023025897834626444\n",
      "  (49, 36)\t0.21944521826598395\n",
      "  (49, 32)\t0.026802190054823306\n",
      "  (49, 0)\t0.019541924032929706\n"
     ]
    }
   ],
   "source": [
    "print(vect_abstrak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diatas ini merupakan daftar TF-IDF didalam setiap dokumen yang nilainya bukan 0 (terdapat kata yang muncul)<br>\n",
    "Contohnya pada dokumen index ke 9 dengan kata yang berada di index ke 4, muncul beberapa kata sehingga muncul hasil perhitungan TF-IDF-nya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Menampilkan data hasil pemrosesan TD-IDF kedalam bentuk DataFrame agar lebih mudah dibaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abstrak', 'abtrak', 'accidental', ..., 'xl', 'yamaha', 'yustina'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term=vectorizer.get_feature_names_out()\n",
    "term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variabel \"term\" berisi daftar list kata didalam corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>abstrak</th>\n",
       "      <th>abtrak</th>\n",
       "      <th>accidental</th>\n",
       "      <th>acer</th>\n",
       "      <th>action</th>\n",
       "      <th>adaro</th>\n",
       "      <th>adira</th>\n",
       "      <th>adjusted</th>\n",
       "      <th>adnya</th>\n",
       "      <th>adukkan</th>\n",
       "      <th>...</th>\n",
       "      <th>volume</th>\n",
       "      <th>wanita</th>\n",
       "      <th>wantara</th>\n",
       "      <th>wawancara</th>\n",
       "      <th>whichsuch</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>windows</th>\n",
       "      <th>xl</th>\n",
       "      <th>yamaha</th>\n",
       "      <th>yustina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1040 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abstrak abtrak accidental acer action adaro adira  adjusted adnya adukkan  \\\n",
       "0  0.033032    0.0        0.0  0.0    0.0   0.0   0.0  0.000000   0.0     0.0   \n",
       "1  0.000000    0.0        0.0  0.0    0.0   0.0   0.0  0.000000   0.0     0.0   \n",
       "2  0.000000    0.0        0.0  0.0    0.0   0.0   0.0  0.000000   0.0     0.0   \n",
       "3  0.000000    0.0        0.0  0.0    0.0   0.0   0.0  0.000000   0.0     0.0   \n",
       "4  0.000000    0.0        0.0  0.0    0.0   0.0   0.0  0.054676   0.0     0.0   \n",
       "\n",
       "   ... volume wanita   wantara wawancara whichsuch wilayah   windows   xl  \\\n",
       "0  ...    0.0    0.0  0.000000  0.000000       0.0     0.0  0.000000  0.0   \n",
       "1  ...    0.0    0.0  0.000000  0.041236       0.0     0.0  0.000000  0.0   \n",
       "2  ...    0.0    0.0  0.000000  0.000000       0.0     0.0  0.072762  0.0   \n",
       "3  ...    0.0    0.0  0.066789  0.000000       0.0     0.0  0.000000  0.0   \n",
       "4  ...    0.0    0.0  0.000000  0.000000       0.0     0.0  0.000000  0.0   \n",
       "\n",
       "  yamaha yustina  \n",
       "0    0.0     0.0  \n",
       "1    0.0     0.0  \n",
       "2    0.0     0.0  \n",
       "3    0.0     0.0  \n",
       "4    0.0     0.0  \n",
       "\n",
       "[5 rows x 1040 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Tf_Idf =pd.DataFrame(data=vect_abstrak.toarray(), columns=[term])\n",
    "df_Tf_Idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1040)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Tf_Idf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil diatas dapat diketahui kata-kata yang tidak muncul didalam setiap dokumen memiliki nilai TF-IDF nol (0) sedangkan kata-kata yang muncul memiliki nilainya masing-masing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Penerapan LSA (Latent Semantic Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA dapat digunakan untuk mengekstrak topik yang tidak secara tersurat dapat dibaca dari sebuah kumpulan dokumen.<br>\n",
    "\n",
    "A = σ Σ U<br>\n",
    "\n",
    "Komputasi dasar yang ada di dalam LSA adalah perhitungan dua matriks yang berisi vektor eigen, umumnya dinotasikan sebagai σ dan U, serta satu matriks diagonal, umumnya dinotasikan sebagai Σ, yang kesemuanya mengkonstruksi sebuah matriks A, yaitu korpus atau kumpulan dokumen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Pemrosesan LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_model = TruncatedSVD(n_components=15, algorithm='randomized', n_iter=10)\n",
    "lsa_top=lsa_model.fit_transform(vect_abstrak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> code diatas menggunakan n_components sebanyak 5, artinya kita akan meranking term yang frecuencynya sering muncul sebanyak 5 peringkat. dengan menggunakan algoritma random dan iteriasi sebanyak 10x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.82051614e-01  1.35204668e-01 -8.88126273e-02  9.22889218e-02\n",
      "  -9.60919179e-02  1.93385122e-01  2.50560181e-01  8.15198259e-02\n",
      "  -1.02142525e-01 -1.62041198e-02  5.67876641e-02 -1.76189648e-01\n",
      "   2.69933858e-02  1.68234280e-01 -3.02622207e-01]\n",
      " [ 5.00454023e-01 -8.16800211e-02 -1.59107963e-01 -1.91495948e-01\n",
      "  -1.00424903e-02  3.03903779e-02 -7.39493965e-02 -1.46752714e-01\n",
      "   9.95338044e-02  3.76084351e-01 -4.42266271e-02  4.66627343e-02\n",
      "  -5.77373015e-02 -3.44118203e-02  7.38763423e-02]\n",
      " [ 2.90048188e-01  1.74429053e-02  7.45231856e-02 -5.34326695e-02\n",
      "   5.33384695e-02  8.39954358e-02  1.70723636e-01 -3.83124277e-03\n",
      "  -1.74594538e-01 -1.45454494e-01  2.70369659e-02  2.74564325e-01\n",
      "  -1.96661662e-01 -5.46444040e-03  5.31154696e-02]\n",
      " [ 2.60549520e-01  1.09199953e-02 -3.62016504e-02  2.40599625e-02\n",
      "  -9.68371598e-02 -8.90158633e-02  2.40286368e-01 -1.64663094e-01\n",
      "   2.53577513e-01  5.25898700e-01 -3.36422853e-02 -2.80631676e-02\n",
      "   1.18114561e-03 -5.71386244e-02  2.61795744e-02]\n",
      " [ 5.06158677e-01 -5.02796248e-02 -9.16322537e-02 -1.39586217e-01\n",
      "  -1.97403067e-02  4.68083557e-02 -6.40996333e-02 -1.24451538e-01\n",
      "   3.47725811e-01 -2.23237212e-02 -9.03461260e-02 -1.09776011e-01\n",
      "  -4.05800444e-02  1.34420635e-02  1.09193656e-01]\n",
      " [ 2.02030605e-01  3.62655467e-01 -3.08372661e-02  1.57075245e-01\n",
      "  -1.22388050e-02  4.30211224e-01 -1.02614880e-01 -1.02747279e-01\n",
      "   1.20811974e-01 -1.50475913e-01 -1.38864832e-01 -5.46036764e-02\n",
      "   2.05863781e-01 -3.72468741e-01  8.74453124e-02]\n",
      " [ 2.42158851e-01  1.00672725e-01  3.10725591e-01  1.48522607e-01\n",
      "   2.29740661e-01 -5.08975711e-02  1.17137353e-03  1.94981797e-01\n",
      "   1.53268986e-01  1.20962035e-01  3.75899912e-01 -1.35707215e-01\n",
      "   9.11366407e-02  5.69678181e-02 -5.62850724e-03]\n",
      " [ 8.39848119e-02  1.03904574e-01  2.63140927e-02 -5.79216637e-02\n",
      "  -4.79490309e-02  5.26898636e-02 -1.24616277e-02  1.96608630e-02\n",
      "  -1.22686422e-01  5.29121227e-02  1.46094421e-01  2.55597547e-02\n",
      "  -4.73326305e-02  4.08773767e-01 -5.94796022e-03]\n",
      " [ 1.86109892e-01  3.43027106e-02  6.65263053e-02  1.88616657e-01\n",
      "  -3.63566716e-02 -7.02784623e-02  1.28826609e-01 -5.62099407e-02\n",
      "  -3.42865179e-02 -2.69750559e-01 -6.32021079e-02  1.24834892e-01\n",
      "  -3.69750262e-01 -2.97095177e-02  4.87446681e-01]\n",
      " [ 6.03748714e-01 -1.40078169e-01 -9.19557492e-02 -3.86418029e-01\n",
      "   9.27599663e-02  1.61214629e-01 -5.28705072e-02  1.22383267e-01\n",
      "  -1.01061416e-01 -3.44457705e-02  1.35350361e-02 -4.88754111e-02\n",
      "  -1.96650240e-03  6.60267513e-02  8.19051125e-02]\n",
      " [ 2.02502681e-01  1.96724802e-01  4.81379860e-01 -2.03429196e-01\n",
      "  -3.77439152e-01 -8.04179680e-02 -1.19942157e-01 -6.22601967e-02\n",
      "  -1.77791175e-01  1.02935499e-01 -1.52074651e-01  2.76736803e-02\n",
      "   2.68869835e-02 -9.87919743e-02 -3.24568663e-02]\n",
      " [ 2.03392531e-02  1.58678650e-02  2.05824482e-02  3.99888646e-02\n",
      "   4.43246258e-03  6.51827538e-03  2.20605111e-02  4.10113178e-03\n",
      "   8.00169764e-02 -6.36829544e-03  4.41860071e-02  2.75692105e-02\n",
      "   1.88293627e-01  2.32217537e-01 -3.43299436e-01]\n",
      " [ 1.51976682e-01  5.93342949e-01 -3.66552775e-01 -2.22945531e-01\n",
      "   1.23824789e-01 -4.99140817e-01  5.36514373e-02  3.91684994e-03\n",
      "   1.05061119e-02 -5.32554961e-02 -2.40725492e-02  1.13034514e-02\n",
      "   1.88267846e-02 -7.17361799e-03  3.43340272e-02]\n",
      " [ 2.13439506e-01 -1.78402117e-02  3.75650884e-03 -1.73488511e-02\n",
      "   1.15156988e-02  3.85426028e-02 -1.66552236e-02 -3.59236525e-03\n",
      "  -1.04516947e-01 -4.64713714e-02  6.11868769e-02  3.07841597e-01\n",
      "  -1.84872725e-01 -2.30294916e-03 -3.08037219e-01]\n",
      " [ 9.19240719e-02  4.92734025e-01 -1.44790556e-01  1.40807265e-01\n",
      "   3.10236204e-02  3.19532016e-01 -8.04662440e-02  4.47696220e-02\n",
      "  -1.47507713e-01  1.66822295e-01 -2.18622314e-02  1.55522297e-02\n",
      "  -1.53504289e-01  3.05712887e-01 -5.54159363e-03]\n",
      " [ 2.42852204e-01  9.82840764e-03  2.85603580e-02  1.33315309e-01\n",
      "  -1.27288254e-01 -4.26612970e-03  2.78698399e-01 -1.77350469e-01\n",
      "   3.74404233e-01 -4.76501280e-02 -8.34042443e-02  3.04234949e-02\n",
      "   9.94895556e-02  1.10022272e-01 -2.29683697e-01]\n",
      " [ 4.36888747e-01 -7.16738802e-02  4.88956047e-02  1.04445883e-02\n",
      "   1.85915519e-01 -6.35364043e-03 -1.07897488e-01 -6.32102288e-03\n",
      "   5.28860335e-02  4.95496822e-02  5.29657071e-02  1.57587215e-01\n",
      "   9.72931667e-02 -2.05571677e-01 -1.42444330e-02]\n",
      " [ 5.39349350e-01 -9.37253055e-02 -1.47640733e-01 -1.72393138e-02\n",
      "  -1.11454512e-01  4.21072535e-03  1.38860718e-01  8.26728413e-02\n",
      "   1.54315649e-01 -6.45441481e-02 -4.56703973e-02 -8.04129042e-02\n",
      "  -4.41809325e-02  3.99262794e-02 -9.77292362e-02]\n",
      " [ 1.07999564e-01  5.87875834e-03 -5.64991519e-02  1.16051680e-01\n",
      "  -1.88706124e-01 -1.55603768e-02  5.11048618e-01 -3.86619644e-02\n",
      "  -1.29010657e-01  1.05687011e-01  6.16671944e-02 -1.36297589e-01\n",
      "   1.79361470e-01 -1.06326152e-01 -1.13345742e-03]\n",
      " [ 2.52173691e-01  3.34403236e-02  7.70084525e-02  2.26924473e-01\n",
      "  -9.79364496e-03 -1.01208405e-01  5.01829489e-02  6.35240287e-01\n",
      "   1.40961356e-01  9.75137814e-02 -9.01463279e-02  1.04075602e-01\n",
      "  -1.19460877e-01 -3.01694506e-02  8.97729367e-03]\n",
      " [ 1.87079707e-01  4.31358024e-01 -9.57318156e-03  1.88696413e-01\n",
      "  -8.25541865e-03  5.18947855e-01 -5.55680359e-02 -6.35272384e-02\n",
      "   3.31225712e-02 -6.37696554e-02 -9.84068686e-02 -5.19258488e-02\n",
      "   1.35817671e-01 -2.62656234e-01  4.12993019e-03]\n",
      " [ 1.85815253e-01  5.47854710e-03  7.82855530e-02  5.20953296e-02\n",
      "  -1.42009996e-02 -4.97693083e-03  1.88032795e-03 -1.62689480e-01\n",
      "   2.20985241e-01 -3.19264451e-01 -1.64756396e-01  1.48444332e-02\n",
      "  -2.70521698e-01  1.12709867e-01 -3.27723065e-01]\n",
      " [ 1.15398297e-01  5.24797022e-01 -8.86442765e-02  2.02512726e-01\n",
      "   1.53770329e-02  3.65649122e-01 -1.02628697e-01  1.04676204e-01\n",
      "  -6.86048434e-02  1.44452697e-01  2.54322984e-02  1.44528792e-02\n",
      "  -1.01505074e-01  2.02955353e-01  5.53980062e-02]\n",
      " [ 1.56567937e-01  6.39151412e-02  1.64136743e-01  1.26517173e-01\n",
      "  -8.49434008e-02 -9.01205164e-02 -5.69349427e-02  2.99567532e-01\n",
      "   1.89139382e-01 -3.94640646e-02 -1.10221219e-01 -7.00837494e-02\n",
      "  -9.00017356e-02  1.91085051e-02 -7.41601362e-03]\n",
      " [ 2.63764124e-01  3.17243389e-02  3.57002655e-01 -8.57117994e-02\n",
      "   6.35658024e-01  2.83917906e-02  1.84929208e-01 -8.35459189e-02\n",
      "  -8.66568652e-02  5.18235506e-02 -7.51563533e-03 -8.50766893e-02\n",
      "   8.18248227e-02 -9.09191015e-04  3.92223643e-02]\n",
      " [ 1.32449577e-01  1.43769722e-01  2.63648681e-01 -2.01131769e-02\n",
      "  -1.31374132e-01  1.49151641e-02 -8.16762530e-03 -1.02180212e-02\n",
      "   1.19291329e-01 -8.79562342e-03  6.31221375e-01 -8.11358072e-02\n",
      "  -2.00159701e-02  5.49878824e-02  8.89147090e-02]\n",
      " [ 2.43804947e-01  1.51648543e-01  2.82930178e-01 -1.08828319e-01\n",
      "  -2.22673442e-01 -1.31760885e-02 -7.94766216e-03 -1.33714149e-01\n",
      "   1.03971798e-01 -1.39191046e-01  2.99129240e-01  4.92540965e-02\n",
      "  -9.75608872e-02 -7.23299742e-02  1.51499532e-02]\n",
      " [ 1.63984432e-01  1.72678392e-01  4.83161168e-01 -2.80739313e-01\n",
      "  -3.61995764e-01 -9.72722759e-02 -1.28217633e-01  2.13711496e-02\n",
      "  -1.89190805e-01  4.15121434e-02 -2.88554103e-01 -1.05366547e-01\n",
      "   6.10780287e-02  2.01584456e-02 -3.92919169e-02]\n",
      " [ 8.55660006e-02  3.62050842e-02  4.35445065e-02  7.03979939e-02\n",
      "  -5.43798168e-02 -5.12213463e-02  3.28888554e-02 -1.04064278e-02\n",
      "   1.32296007e-01 -4.33442063e-02 -8.40066557e-02  5.07016533e-01\n",
      "   3.99360030e-01  2.78310241e-01  2.27324079e-01]\n",
      " [ 1.16848496e-01  1.15567639e-01  3.33020824e-01 -1.83142376e-02\n",
      "  -1.83711524e-01 -1.26449560e-01 -2.73856041e-02  2.44697016e-01\n",
      "  -4.64106847e-02  1.50075106e-01 -3.40204118e-01 -5.71298504e-02\n",
      "   1.06860800e-01  5.12875524e-02  2.79424456e-02]\n",
      " [ 6.61115591e-02  3.17146143e-01 -1.02558533e-01 -1.39531122e-01\n",
      "  -3.88350802e-03 -2.93150431e-01  2.92379369e-02 -1.22291043e-02\n",
      "   2.68307958e-02 -2.05052565e-01  1.30272330e-01 -5.61805624e-02\n",
      "   1.02086585e-01 -2.65787616e-01 -1.92611627e-01]\n",
      " [ 1.55391462e-01  1.66132909e-01  3.34410301e-01 -1.24614055e-01\n",
      "  -2.47496262e-01 -2.98341842e-02 -3.66939205e-02 -5.89970093e-02\n",
      "  -1.62132880e-02  1.70725245e-03  3.52228967e-01 -5.15058308e-03\n",
      "   2.55233855e-02 -3.49493070e-02  8.06102757e-02]\n",
      " [ 2.90308082e-01 -1.53399220e-02  1.21242942e-01  1.66859789e-01\n",
      "   2.06816032e-01 -9.30207343e-02 -5.96842071e-02  5.32608306e-01\n",
      "   1.76543026e-01  8.66419309e-02  2.95568402e-02  1.40181332e-01\n",
      "   1.08947941e-02 -2.16278380e-01 -7.25588307e-02]\n",
      " [ 4.60368111e-01 -5.94495500e-02  2.35626469e-02  5.31812024e-01\n",
      "  -3.62441780e-02 -2.56147116e-01 -2.20182781e-01 -1.52901600e-01\n",
      "  -6.02097154e-02 -1.63707821e-01 -3.17465426e-02 -1.96419128e-01\n",
      "  -7.42328066e-02  9.36439360e-02  9.71991664e-02]\n",
      " [ 4.00284888e-01 -1.24401475e-01 -1.50726540e-01  1.31496326e-02\n",
      "  -1.40286804e-01  5.75130386e-02  4.00495228e-01  1.54568089e-01\n",
      "  -3.65206360e-01 -4.85254947e-02  5.84566467e-02  4.23668062e-02\n",
      "   9.57642393e-02 -8.13643961e-02 -7.47874045e-03]\n",
      " [ 3.79932490e-01 -1.40101327e-02 -5.63257385e-02  2.65715803e-01\n",
      "  -2.20564601e-01 -1.00887332e-01  4.54664250e-01 -7.21593421e-02\n",
      "  -9.56888937e-02  6.05859778e-02 -3.06416514e-02 -7.88905833e-02\n",
      "  -9.65780805e-02 -2.63068783e-02  1.84628495e-01]\n",
      " [ 1.15982227e-01  6.82847337e-01 -3.63658782e-01 -1.56983793e-01\n",
      "   1.38677072e-01 -4.15237243e-01  1.04985621e-02  9.18222607e-03\n",
      "  -5.00694332e-02 -3.68354141e-02 -2.08149891e-02  2.10813786e-02\n",
      "   1.75622603e-02  2.58123417e-02  1.85028117e-02]\n",
      " [ 8.16398684e-02  6.29136593e-02  2.70170106e-02  2.15699516e-02\n",
      "  -3.81966508e-02  2.74961007e-02 -1.82155572e-03 -9.88324901e-02\n",
      "  -5.78243168e-02  1.85347520e-01  7.10873564e-02  4.02246545e-01\n",
      "  -3.68663746e-01 -2.45963326e-01 -2.25148802e-01]\n",
      " [ 4.32298772e-01 -2.71178957e-02 -1.76804378e-02 -1.49466086e-01\n",
      "   2.91066020e-03  6.78180406e-02 -1.40248701e-01 -2.27200135e-02\n",
      "   1.50937710e-01 -1.83785430e-01  2.78258578e-02 -6.92474205e-02\n",
      "   1.09614797e-02 -4.19672914e-02 -3.39862127e-02]\n",
      " [ 3.20951948e-01 -1.13897652e-01 -6.69842647e-02  4.13607069e-02\n",
      "   3.70135360e-02  2.51514404e-04 -8.62581552e-02  5.93038319e-02\n",
      "  -3.61219794e-01 -1.34054588e-01  6.31771047e-02  1.24825867e-01\n",
      "   2.69654140e-01 -6.17243405e-02 -1.14243043e-01]\n",
      " [ 6.53460615e-01 -7.80238258e-02 -1.38988714e-01 -4.47052604e-02\n",
      "  -1.02976627e-01  4.32359995e-02  1.62964044e-01 -1.86145909e-02\n",
      "   1.03898074e-01 -5.05045010e-02 -3.72998267e-02 -2.76739556e-02\n",
      "  -1.91091975e-02  7.03282381e-03 -5.25203487e-02]\n",
      " [ 4.68237508e-01 -9.51980918e-02  7.00009442e-03  4.78629012e-01\n",
      "   4.74318032e-03 -2.52827331e-01 -3.40527625e-01 -1.36968794e-01\n",
      "  -1.44279874e-01 -5.03698742e-02 -4.79330204e-03 -1.93407182e-01\n",
      "   4.25421728e-02  8.59780061e-02 -6.21701980e-02]\n",
      " [ 4.38421304e-01 -3.45952674e-02 -9.07515722e-02  1.33336517e-01\n",
      "   1.16389054e-02 -9.94234599e-02 -2.56893051e-01 -2.54574609e-01\n",
      "  -1.08077113e-01  3.87991339e-01  2.73324738e-02  1.13699567e-01\n",
      "  -7.91331730e-02 -7.78954923e-02 -8.95450323e-02]\n",
      " [ 1.65379529e-01  5.04375926e-02  8.70919386e-02  1.42706321e-02\n",
      "  -9.38375355e-02  1.95075314e-02  2.85419726e-02 -1.11300501e-01\n",
      "   2.29498861e-01 -1.73833818e-01 -2.17665540e-02  3.90930384e-01\n",
      "   2.44490140e-01  1.80883743e-01  1.03237625e-01]\n",
      " [ 2.08409510e-01  1.31229478e-01  4.58354087e-01 -8.58330460e-02\n",
      "   2.29116704e-01 -2.61700097e-02  1.75712841e-01 -1.20400863e-01\n",
      "  -7.42508992e-02 -7.63511926e-02 -2.22200015e-01 -1.54752051e-02\n",
      "  -1.12155026e-01  9.77123743e-02 -1.09578509e-01]\n",
      " [ 5.31902063e-01 -1.39290846e-01 -1.63503003e-01 -3.82430195e-01\n",
      "   3.61776913e-02  1.09113791e-01 -1.29966173e-01  8.10371626e-02\n",
      "   1.03793713e-01 -1.02204320e-02 -4.31225371e-02 -1.58105149e-01\n",
      "  -6.72504922e-02  9.64691782e-02  7.89955278e-02]\n",
      " [ 6.09908113e-01 -1.42939354e-01 -7.48568083e-02  6.90915630e-02\n",
      "  -1.66852838e-02 -7.36592659e-03 -9.39615582e-02  8.30791327e-02\n",
      "  -2.16317535e-01 -2.28470837e-01  4.94103729e-02  5.98312722e-02\n",
      "   7.21758469e-02 -4.28180830e-02 -4.70604439e-02]\n",
      " [ 4.64675224e-01 -1.26638607e-01 -6.47849268e-02  1.25843415e-01\n",
      "   5.62581179e-02 -8.58613011e-02 -1.70829239e-01 -1.65527589e-01\n",
      "  -1.05425295e-01  2.03255090e-01  1.29261351e-02  9.03095769e-02\n",
      "   2.01326009e-01  3.89356559e-02  1.51408037e-02]\n",
      " [ 5.14967568e-01 -1.35871444e-01 -1.32850114e-01 -3.32552693e-01\n",
      "   2.89254306e-02  1.43662955e-01 -5.02074132e-02  1.50766723e-01\n",
      "  -7.35711505e-02 -3.58857941e-02  2.67606941e-02 -5.70181710e-02\n",
      "  -3.20692201e-02  9.60484922e-02  8.53732423e-02]\n",
      " [ 1.93469100e-01  6.12553252e-02  3.63053128e-01  4.18939735e-03\n",
      "   6.24509707e-01 -8.74942960e-03  2.24997742e-01 -1.97510476e-01\n",
      "  -5.00605459e-02  1.34714507e-02 -8.80346247e-02 -3.71910379e-02\n",
      "   5.75436482e-04  2.20937427e-02  2.95800174e-02]]\n",
      "(50, 15)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_top)\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  18.205161445378927\n",
      "Topic  1  :  13.52046677610753\n",
      "Topic  2  :  -8.881262727629384\n",
      "Topic  3  :  9.228892177459395\n",
      "Topic  4  :  -9.609191790876164\n",
      "Topic  5  :  19.338512187804945\n",
      "Topic  6  :  25.056018053619667\n",
      "Topic  7  :  8.151982589048938\n",
      "Topic  8  :  -10.214252479396729\n",
      "Topic  9  :  -1.6204119814993687\n",
      "Topic  10  :  5.678766413481274\n",
      "Topic  11  :  -17.618964765967878\n",
      "Topic  12  :  2.6993385757596378\n",
      "Topic  13  :  16.823427972576567\n",
      "Topic  14  :  -30.26222069994421\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "    print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 1040)\n",
      "[[ 0.04091055  0.00150155  0.0183335  ...  0.06173515  0.02013753\n",
      "   0.0033966 ]\n",
      " [ 0.00994799  0.00386318 -0.00554698 ... -0.02247342 -0.00181417\n",
      "   0.00029072]\n",
      " [ 0.02366525  0.01175586 -0.00265594 ...  0.03322114 -0.00793134\n",
      "   0.00158197]\n",
      " ...\n",
      " [ 0.01905206  0.00280096  0.00135504 ...  0.02206835 -0.02479795\n",
      "  -0.01078248]\n",
      " [ 0.01383387  0.00105396 -0.00045702 ...  0.02563701 -0.00615604\n",
      "  -0.0008762 ]\n",
      " [-0.0217116  -0.00176383 -0.02886077 ...  0.04028395  0.0477196\n",
      "  -0.01089137]]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape) # (no_of_topics*no_of_words)\n",
    "print(lsa_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "variabel keputusan pembelian produk harga uji merek penelitian berpengaruh promosi kualitas konsumen bangkalan signifikan pengaruh distribusi simultan parsial analisis swalayan \n",
      "\n",
      "Topic 1: \n",
      "perusahaan saham split stock ratio return akuisisi penelitian terdaftar kerja perbedaan indonesia bursa efek current equity perdagangan karyawan manufaktur volume \n",
      "\n",
      "Topic 2: \n",
      "kerja pesan karyawan langsung pln iklan karir pengembangan pengaruh stressor prestasi semangat kompensasi komunikasi persero pendidikan kinerja faktor variabel gresik \n",
      "\n",
      "Topic 3: \n",
      "merek persepsi ekuitas kualitas perusahaan loyalitas ratio trunojoyo mahasiswa madura universitas online asosiasi kesadaran ekonomi faktor fakultas notebook blackberry brand \n",
      "\n",
      "Topic 4: \n",
      "pesan iklan isi konsumen xl kartu seluler televisi format sumber beli saham kecamatan struktur geger keputusan angin jamu manyar muncul \n",
      "\n",
      "Topic 5: \n",
      "ratio perusahaan current equity profitabilitas akuisisi terdaftar manufaktur debt roe produk promosi bursa efek firm leverage risk size distribusi businees \n",
      "\n",
      "Topic 6: \n",
      "motor kualitas sepeda pesan kepuasan produk pelayanan jembatan suramadu pelanggan pengguna bangkalan yamaha jupiter new kemudahan honda petugas biaya atribut \n",
      "\n",
      "Topic 7: \n",
      "online faktor produk trunojoyo mahasiswa madura universitas iklan pakaian fakultas fashion ekonomi belanja preferensi stressor akademik pembelian klik langsung menentukan \n",
      "\n",
      "Topic 8: \n",
      "harga variabel berdasarkan pelayanan online promosi kepuasan berpengaruh terikat konflik keluarga pasien pekerjaan mix langsung berbelanja sikap rumah lokasi atmosfer \n",
      "\n",
      "Topic 9: \n",
      "swalayan harga jerry tom berbelanja perusahaan eceran sidogiri kepuasan pelayanan kopontren merah tanah bauran konsumen indah cabang stressor fisik bangkalan \n",
      "\n",
      "Topic 10: \n",
      "kompensasi langsung finansial kinerja karyawan gresik rekrutmen pt nonfinansial kantor pendidikan fhitung produktivitas cdm jalur pos cabang iklan pelatihan alat \n",
      "\n",
      "Topic 11: \n",
      "budaya keluarga konflik pengemis pekerjaan bangkalan perilaku piutang cabang bundling koperasi rentabilitas sidogiri online anak coffee top bmt kopergu kpri \n",
      "\n",
      "Topic 12: \n",
      "budaya keluarga pengemis perilaku kamal ratio konflik ibu pekerjaan atribut lingkungan equity current service research anak jembatan suramadu cair indomilk \n",
      "\n",
      "Topic 13: \n",
      "perusahaan bersaing inovasi keunggulan budaya keluarga pengemis lamongan kinerja akuisisi optik reza konflik pekerjaan pemasaran research perilaku bangkrut kritis sehat \n",
      "\n",
      "Topic 14: \n",
      "persepsi banking internet kemudahan bri ulang budaya minat pengemis layanan promosi keluarga keamanan ketersediaan manfaat harga kota fitur kompensasi kecuali \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
